// *** WARNING: this file was generated by pulumi-language-nodejs. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

export interface BigquerySemanticLayerCredentialConfiguration {
    /**
     * The adapter version
     */
    adapterVersion: pulumi.Input<string>;
    /**
     * The name of the configuration
     */
    name: pulumi.Input<string>;
    /**
     * The ID of the project
     */
    projectId: pulumi.Input<number>;
}

export interface BigquerySemanticLayerCredentialCredential {
    /**
     * The internal credential ID
     */
    credentialId?: pulumi.Input<number>;
    /**
     * Default dataset name
     */
    dataset: pulumi.Input<string>;
    /**
     * The ID of this resource. Contains the project ID and the credential ID.
     */
    id?: pulumi.Input<string>;
    /**
     * Whether the BigQuery credential is active
     */
    isActive?: pulumi.Input<boolean>;
    /**
     * Number of threads to use
     */
    numThreads: pulumi.Input<number>;
    /**
     * Project ID to create the BigQuery credential in
     */
    projectId: pulumi.Input<number>;
}

export interface DatabricksSemanticLayerCredentialConfiguration {
    /**
     * The adapter version
     */
    adapterVersion: pulumi.Input<string>;
    /**
     * The name of the configuration
     */
    name: pulumi.Input<string>;
    /**
     * The ID of the project
     */
    projectId: pulumi.Input<number>;
}

export interface DatabricksSemanticLayerCredentialCredential {
    /**
     * The type of the adapter (databricks or spark). Optional only when semantic*layer*credential is set to true; otherwise, this field is required.
     */
    adapterType?: pulumi.Input<string>;
    /**
     * The catalog where to create models (only for the databricks adapter)
     */
    catalog?: pulumi.Input<string>;
    /**
     * The system Databricks credential ID
     */
    credentialId?: pulumi.Input<number>;
    /**
     * The ID of this resource. Contains the project ID and the credential ID.
     */
    id?: pulumi.Input<string>;
    /**
     * Project ID to create the Databricks credential in
     */
    projectId: pulumi.Input<number>;
    /**
     * The schema where to create models. Optional only when semantic*layer*credential is set to true; otherwise, this field is required.
     */
    schema?: pulumi.Input<string>;
    /**
     * This field indicates that the credential is used as part of the Semantic Layer configuration. It is used to create a Databricks credential for the Semantic Layer.
     */
    semanticLayerCredential?: pulumi.Input<boolean>;
    /**
     * Target name
     *
     * @deprecated This field is deprecated at the environment level (it was never possible to set it in the UI) and will be removed in a future release. Please remove it and set the target name at the job level or leverage environment variables.
     */
    targetName?: pulumi.Input<string>;
    /**
     * Token for Databricks user
     */
    token: pulumi.Input<string>;
}

export interface GetJobJobCompletionTriggerCondition {
    /**
     * The ID of the job that would trigger this job after completion.
     */
    jobId?: number;
    /**
     * The ID of the project where the trigger job is running in.
     */
    projectId?: number;
    /**
     * List of statuses to trigger the job on.
     */
    statuses?: string[];
}

export interface GetJobJobCompletionTriggerConditionArgs {
    /**
     * The ID of the job that would trigger this job after completion.
     */
    jobId?: pulumi.Input<number>;
    /**
     * The ID of the project where the trigger job is running in.
     */
    projectId?: pulumi.Input<number>;
    /**
     * List of statuses to trigger the job on.
     */
    statuses?: pulumi.Input<pulumi.Input<string>[]>;
}

export interface GetRunsFilter {
    /**
     * The ID of the environment
     */
    environmentId?: number;
    /**
     * The ID of the job definition
     */
    jobDefinitionId?: number;
    /**
     * The limit of the runs
     */
    limit?: number;
    /**
     * The ID of the project
     */
    projectId?: number;
    /**
     * The ID of the pull request
     */
    pullRequestId?: number;
    /**
     * The status of the run
     */
    status?: number;
    /**
     * The status of the run
     */
    statusIn?: string;
    /**
     * The ID of the trigger
     */
    triggerId?: number;
}

export interface GetRunsFilterArgs {
    /**
     * The ID of the environment
     */
    environmentId?: pulumi.Input<number>;
    /**
     * The ID of the job definition
     */
    jobDefinitionId?: pulumi.Input<number>;
    /**
     * The limit of the runs
     */
    limit?: pulumi.Input<number>;
    /**
     * The ID of the project
     */
    projectId?: pulumi.Input<number>;
    /**
     * The ID of the pull request
     */
    pullRequestId?: pulumi.Input<number>;
    /**
     * The status of the run
     */
    status?: pulumi.Input<number>;
    /**
     * The status of the run
     */
    statusIn?: pulumi.Input<string>;
    /**
     * The ID of the trigger
     */
    triggerId?: pulumi.Input<number>;
}

export interface GetServiceTokenServiceTokenPermission {
    /**
     * Whether or not to apply this permission to all projects for this service token
     */
    allProjects?: boolean;
    /**
     * Set of permissions to apply
     */
    permissionSet?: string;
    /**
     * Project ID to apply this permission to for this service token
     */
    projectId?: number;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories?: string[];
}

export interface GetServiceTokenServiceTokenPermissionArgs {
    /**
     * Whether or not to apply this permission to all projects for this service token
     */
    allProjects?: pulumi.Input<boolean>;
    /**
     * Set of permissions to apply
     */
    permissionSet?: pulumi.Input<string>;
    /**
     * Project ID to apply this permission to for this service token
     */
    projectId?: pulumi.Input<number>;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories?: pulumi.Input<pulumi.Input<string>[]>;
}

export interface GlobalConnectionApacheSpark {
    /**
     * Auth
     */
    auth?: pulumi.Input<string>;
    /**
     * Spark cluster for the connection
     */
    cluster: pulumi.Input<string>;
    /**
     * Connection retries. Default=0
     */
    connectRetries?: pulumi.Input<number>;
    /**
     * Connection time out in seconds. Default=10
     */
    connectTimeout?: pulumi.Input<number>;
    /**
     * Hostname of the connection
     */
    host: pulumi.Input<string>;
    /**
     * Authentication method for the connection (http or thrift).
     */
    method: pulumi.Input<string>;
    /**
     * Organization ID
     */
    organization?: pulumi.Input<string>;
    /**
     * Port for the connection. Default=443
     */
    port?: pulumi.Input<number>;
    /**
     * User
     */
    user?: pulumi.Input<string>;
}

export interface GlobalConnectionAthena {
    /**
     * Specify the database (data catalog) to build models into (lowercase only).
     */
    database: pulumi.Input<string>;
    /**
     * Number of times to retry boto3 requests (e.g. deleting S3 files for materialized tables).
     */
    numBoto3Retries?: pulumi.Input<number>;
    /**
     * Number of times to retry iceberg commit queries to fix ICEBERG*COMMIT*ERROR.
     */
    numIcebergRetries?: pulumi.Input<number>;
    /**
     * Number of times to retry a failing query.
     */
    numRetries?: pulumi.Input<number>;
    /**
     * Interval in seconds to use for polling the status of query results in Athena.
     */
    pollInterval?: pulumi.Input<number>;
    /**
     * AWS region of your Athena instance.
     */
    regionName: pulumi.Input<string>;
    /**
     * Prefix for storing tables, if different from the connection's S3 staging directory.
     */
    s3DataDir?: pulumi.Input<string>;
    /**
     * How to generate table paths in the S3 data directory.
     */
    s3DataNaming?: pulumi.Input<string>;
    /**
     * S3 location to store Athena query results and metadata.
     */
    s3StagingDir: pulumi.Input<string>;
    /**
     * Prefix for storing temporary tables, if different from the connection's S3 data directory.
     */
    s3TmpTableDir?: pulumi.Input<string>;
    /**
     * Identifier of Athena Spark workgroup for running Python models.
     */
    sparkWorkGroup?: pulumi.Input<string>;
    /**
     * Identifier of Athena workgroup.
     */
    workGroup?: pulumi.Input<string>;
}

export interface GlobalConnectionBigquery {
    /**
     * OAuth Client ID
     */
    applicationId?: pulumi.Input<string>;
    /**
     * OAuth Client Secret
     */
    applicationSecret?: pulumi.Input<string>;
    /**
     * Auth Provider X509 Cert URL for the Service Account
     */
    authProviderX509CertUrl: pulumi.Input<string>;
    /**
     * Auth URI for the Service Account
     */
    authUri: pulumi.Input<string>;
    /**
     * Service Account email
     */
    clientEmail: pulumi.Input<string>;
    /**
     * Client ID of the Service Account
     */
    clientId: pulumi.Input<string>;
    /**
     * Client X509 Cert URL for the Service Account
     */
    clientX509CertUrl: pulumi.Input<string>;
    /**
     * Dataproc cluster name for PySpark workloads
     */
    dataprocClusterName?: pulumi.Input<string>;
    /**
     * Google Cloud region for PySpark workloads on Dataproc
     */
    dataprocRegion?: pulumi.Input<string>;
    /**
     * Project to bill for query execution
     */
    executionProject?: pulumi.Input<string>;
    /**
     * The GCP project ID to use for the connection
     */
    gcpProjectId: pulumi.Input<string>;
    /**
     * URI for a Google Cloud Storage bucket to host Python code executed via Datapro
     */
    gcsBucket?: pulumi.Input<string>;
    /**
     * Service Account to impersonate when running queries
     */
    impersonateServiceAccount?: pulumi.Input<string>;
    /**
     * Maximum timeout for the job creation step
     */
    jobCreationTimeoutSeconds?: pulumi.Input<number>;
    /**
     * Total number of seconds to wait while retrying the same query
     */
    jobRetryDeadlineSeconds?: pulumi.Input<number>;
    /**
     * Location to create new Datasets in
     */
    location?: pulumi.Input<string>;
    /**
     * Max number of bytes that can be billed for a given BigQuery query
     */
    maximumBytesBilled?: pulumi.Input<number>;
    /**
     * The priority with which to execute BigQuery queries (batch or interactive)
     */
    priority?: pulumi.Input<string>;
    /**
     * Private Key for the Service Account
     */
    privateKey: pulumi.Input<string>;
    /**
     * Private Key ID for the Service Account
     */
    privateKeyId: pulumi.Input<string>;
    /**
     * Number of retries for queries
     */
    retries?: pulumi.Input<number>;
    /**
     * OAuth scopes for the BigQuery connection
     */
    scopes?: pulumi.Input<pulumi.Input<string>[]>;
    /**
     * Timeout in seconds for queries
     */
    timeoutSeconds?: pulumi.Input<number>;
    /**
     * Token URI for the Service Account
     */
    tokenUri: pulumi.Input<string>;
}

export interface GlobalConnectionDatabricks {
    /**
     * Catalog name if Unity Catalog is enabled in your Databricks workspace.
     */
    catalog?: pulumi.Input<string>;
    /**
     * Required to enable Databricks OAuth authentication for IDE developers.
     */
    clientId?: pulumi.Input<string>;
    /**
     * Required to enable Databricks OAuth authentication for IDE developers.
     */
    clientSecret?: pulumi.Input<string>;
    /**
     * The hostname of the Databricks cluster or SQL warehouse.
     */
    host: pulumi.Input<string>;
    /**
     * The HTTP path of the Databricks cluster or SQL warehouse.
     */
    httpPath: pulumi.Input<string>;
}

export interface GlobalConnectionFabric {
    /**
     * The database to connect to for this connection.
     */
    database: pulumi.Input<string>;
    /**
     * The number of seconds used to establish a connection before failing. Defaults to 0, which means that the timeout is disabled or uses the default system settings.
     */
    loginTimeout?: pulumi.Input<number>;
    /**
     * The port to connect to for this connection. Default=1433
     */
    port?: pulumi.Input<number>;
    /**
     * The number of seconds used to wait for a query before failing. Defaults to 0, which means that the timeout is disabled or uses the default system settings.
     */
    queryTimeout?: pulumi.Input<number>;
    /**
     * The number of automatic times to retry a query before failing. Defaults to 1. Queries with syntax errors will not be retried. This setting can be used to overcome intermittent network issues.
     */
    retries?: pulumi.Input<number>;
    /**
     * The server hostname.
     */
    server: pulumi.Input<string>;
}

export interface GlobalConnectionPostgres {
    /**
     * The database name for this connection.
     */
    dbname: pulumi.Input<string>;
    /**
     * The hostname of the database.
     */
    hostname: pulumi.Input<string>;
    /**
     * The port to connect to for this connection. Default=5432
     */
    port?: pulumi.Input<number>;
    /**
     * PostgreSQL SSH Tunnel configuration
     */
    sshTunnel?: pulumi.Input<inputs.GlobalConnectionPostgresSshTunnel>;
}

export interface GlobalConnectionPostgresSshTunnel {
    /**
     * The hostname for the SSH tunnel.
     */
    hostname: pulumi.Input<string>;
    /**
     * The ID of the SSH tunnel connection.
     */
    id?: pulumi.Input<number>;
    /**
     * The HTTP port for the SSH tunnel.
     */
    port: pulumi.Input<number>;
    /**
     * The SSH public key generated to allow connecting via SSH tunnel.
     */
    publicKey?: pulumi.Input<string>;
    /**
     * The username to use for the SSH tunnel.
     */
    username: pulumi.Input<string>;
}

export interface GlobalConnectionRedshift {
    /**
     * The database name for this connection.
     */
    dbname: pulumi.Input<string>;
    /**
     * The hostname of the data warehouse.
     */
    hostname: pulumi.Input<string>;
    /**
     * The port to connect to for this connection. Default=5432
     */
    port?: pulumi.Input<number>;
    /**
     * Redshift SSH Tunnel configuration
     */
    sshTunnel?: pulumi.Input<inputs.GlobalConnectionRedshiftSshTunnel>;
}

export interface GlobalConnectionRedshiftSshTunnel {
    /**
     * The hostname for the SSH tunnel.
     */
    hostname: pulumi.Input<string>;
    /**
     * The ID of the SSH tunnel connection.
     */
    id?: pulumi.Input<number>;
    /**
     * The HTTP port for the SSH tunnel.
     */
    port: pulumi.Input<number>;
    /**
     * The SSH public key generated to allow connecting via SSH tunnel.
     */
    publicKey?: pulumi.Input<string>;
    /**
     * The username to use for the SSH tunnel.
     */
    username: pulumi.Input<string>;
}

export interface GlobalConnectionSnowflake {
    /**
     * The Snowflake account name
     */
    account: pulumi.Input<string>;
    /**
     * Whether to allow Snowflake OAuth for the connection. If true, the `oauthClientId` and `oauthClientSecret` fields must be set
     */
    allowSso?: pulumi.Input<boolean>;
    /**
     * If true, the snowflake client will keep connections for longer than the default 4 hours. This is helpful when particularly long-running queries are executing (> 4 hours)
     */
    clientSessionKeepAlive?: pulumi.Input<boolean>;
    /**
     * The default database for the connection
     */
    database: pulumi.Input<string>;
    /**
     * OAuth Client ID. Required to allow OAuth between dbt Cloud and Snowflake
     */
    oauthClientId?: pulumi.Input<string>;
    /**
     * OAuth Client Secret. Required to allow OAuth between dbt Cloud and Snowflake
     */
    oauthClientSecret?: pulumi.Input<string>;
    /**
     * The Snowflake role to use when running queries on the connection
     */
    role?: pulumi.Input<string>;
    /**
     * The default Snowflake Warehouse to use for the connection
     */
    warehouse: pulumi.Input<string>;
}

export interface GlobalConnectionStarburst {
    /**
     * The hostname of the account to connect to.
     */
    host: pulumi.Input<string>;
    /**
     * The authentication method. Only LDAP for now.
     */
    method?: pulumi.Input<string>;
    /**
     * The port to connect to for this connection. Default=443
     */
    port?: pulumi.Input<number>;
}

export interface GlobalConnectionSynapse {
    /**
     * The database to connect to for this connection.
     */
    database: pulumi.Input<string>;
    /**
     * The server hostname.
     */
    host: pulumi.Input<string>;
    /**
     * The number of seconds used to establish a connection before failing. Defaults to 0, which means that the timeout is disabled or uses the default system settings.
     */
    loginTimeout?: pulumi.Input<number>;
    /**
     * The port to connect to for this connection. Default=1433
     */
    port?: pulumi.Input<number>;
    /**
     * The number of seconds used to wait for a query before failing. Defaults to 0, which means that the timeout is disabled or uses the default system settings.
     */
    queryTimeout?: pulumi.Input<number>;
    /**
     * The number of automatic times to retry a query before failing. Defaults to 1. Queries with syntax errors will not be retried. This setting can be used to overcome intermittent network issues.
     */
    retries?: pulumi.Input<number>;
}

export interface GlobalConnectionTeradata {
    /**
     * The hostname of the database.
     */
    host: pulumi.Input<string>;
    /**
     * The port to connect to for this connection. Default=1025
     */
    port?: pulumi.Input<string>;
    /**
     * The number of seconds used to establish a connection before failing. Defaults to 0, which means that the timeout is disabled or uses the default system settings.
     */
    requestTimeout?: pulumi.Input<number>;
    /**
     * The number of automatic times to retry a query before failing. Defaults to 1. Queries with syntax errors will not be retried. This setting can be used to overcome intermittent network issues.
     */
    retries?: pulumi.Input<number>;
    /**
     * The transaction mode to use for the connection.
     */
    tmode: pulumi.Input<string>;
}

export interface GroupGroupPermission {
    /**
     * Whether access should be provided for all projects or not.
     */
    allProjects: pulumi.Input<boolean>;
    /**
     * Set of permissions to apply. The permissions allowed are the same as the ones for the `dbtcloud.Group` resource.
     */
    permissionSet: pulumi.Input<string>;
    /**
     * Project ID to apply this permission to for this group.
     */
    projectId?: pulumi.Input<number>;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories?: pulumi.Input<pulumi.Input<string>[]>;
}

export interface GroupPartialPermissionsGroupPermission {
    /**
     * Whether access should be provided for all projects or not.
     */
    allProjects: pulumi.Input<boolean>;
    /**
     * Set of permissions to apply. The permissions allowed are the same as the ones for the `dbtcloud.Group` resource.
     */
    permissionSet: pulumi.Input<string>;
    /**
     * Project ID to apply this permission to for this group.
     */
    projectId?: pulumi.Input<number>;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories?: pulumi.Input<pulumi.Input<string>[]>;
}

export interface IpRestrictionsRuleCidr {
    /**
     * IP CIDR range (can be IPv4 or IPv6)
     */
    cidr?: pulumi.Input<string>;
    /**
     * IPv6 CIDR range (read-only)
     */
    cidrIpv6?: pulumi.Input<string>;
    /**
     * ID of the CIDR range
     */
    id?: pulumi.Input<number>;
    /**
     * ID of the IP restriction rule
     */
    ipRestrictionRuleId?: pulumi.Input<number>;
}

export interface JobJobCompletionTriggerCondition {
    /**
     * The ID of the job that would trigger this job after completion.
     */
    jobId: pulumi.Input<number>;
    /**
     * The ID of the project where the trigger job is running in.
     */
    projectId: pulumi.Input<number>;
    /**
     * List of statuses to trigger the job on. Possible values are `success`, `error` and `canceled`.
     */
    statuses: pulumi.Input<pulumi.Input<string>[]>;
}

export interface JobTriggers {
    /**
     * Whether the job runs automatically on PR creation
     */
    gitProviderWebhook?: pulumi.Input<boolean>;
    /**
     * Whether the job runs automatically on PR creation
     */
    githubWebhook?: pulumi.Input<boolean>;
    /**
     * Whether the job runs automatically once a PR is merged
     */
    onMerge?: pulumi.Input<boolean>;
    /**
     * Whether the job runs on a schedule
     */
    schedule?: pulumi.Input<boolean>;
}

export interface PostgresSemanticLayerCredentialConfiguration {
    /**
     * The adapter version
     */
    adapterVersion: pulumi.Input<string>;
    /**
     * The name of the configuration
     */
    name: pulumi.Input<string>;
    /**
     * The ID of the project
     */
    projectId: pulumi.Input<number>;
}

export interface PostgresSemanticLayerCredentialCredential {
    /**
     * The system Postgres/Redshift/AlloyDB credential ID.
     */
    credentialId?: pulumi.Input<number>;
    /**
     * Default schema name. Optional only when semantic*layer*credential is set to true; otherwise, this field is required.
     */
    defaultSchema?: pulumi.Input<string>;
    /**
     * The ID of this resource. Contains the project ID and the credential ID.
     */
    id?: pulumi.Input<string>;
    /**
     * Whether the Postgres/Redshift/AlloyDB credential is active
     */
    isActive?: pulumi.Input<boolean>;
    /**
     * Number of threads to use (required for Redshift)
     */
    numThreads?: pulumi.Input<number>;
    /**
     * Password for Postgres/Redshift/AlloyDB
     */
    password?: pulumi.Input<string>;
    /**
     * Project ID to create the Postgres/Redshift/AlloyDB credential in.
     */
    projectId: pulumi.Input<number>;
    /**
     * This field indicates that the credential is used as part of the Semantic Layer configuration. It is used to create a Postgres credential for the Semantic Layer.
     */
    semanticLayerCredential?: pulumi.Input<boolean>;
    /**
     * Default schema name
     */
    targetName?: pulumi.Input<string>;
    /**
     * Type of connection. One of (postgres/redshift). Use postgres for alloydb connections. Optional only when semantic*layer*credential is set to true; otherwise, this field is required.
     */
    type?: pulumi.Input<string>;
    /**
     * Username for Postgres/Redshift/AlloyDB
     */
    username: pulumi.Input<string>;
}

export interface RedshiftSemanticLayerCredentialConfiguration {
    /**
     * The adapter version
     */
    adapterVersion: pulumi.Input<string>;
    /**
     * The name of the configuration
     */
    name: pulumi.Input<string>;
    /**
     * The ID of the project
     */
    projectId: pulumi.Input<number>;
}

export interface RedshiftSemanticLayerCredentialCredential {
    /**
     * The internal credential ID
     */
    credentialId?: pulumi.Input<number>;
    /**
     * Default schema name
     */
    defaultSchema: pulumi.Input<string>;
    /**
     * The ID of this resource. Contains the project ID and the credential ID.
     */
    id?: pulumi.Input<string>;
    /**
     * Whether the Redshift credential is active
     */
    isActive?: pulumi.Input<boolean>;
    /**
     * Number of threads to use
     */
    numThreads: pulumi.Input<number>;
    /**
     * The password for the Redshift account
     */
    password?: pulumi.Input<string>;
    /**
     * Project ID to create the Redshift credential in
     */
    projectId: pulumi.Input<number>;
    /**
     * The username for the Redshift account.
     */
    username?: pulumi.Input<string>;
}

export interface ServiceTokenServiceTokenPermission {
    /**
     * Whether or not to apply this permission to all projects for this service token
     */
    allProjects: pulumi.Input<boolean>;
    /**
     * Set of permissions to apply
     */
    permissionSet: pulumi.Input<string>;
    /**
     * Project ID to apply this permission to for this service token
     */
    projectId?: pulumi.Input<number>;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories?: pulumi.Input<pulumi.Input<string>[]>;
}

export interface SnowflakeSemanticLayerCredentialConfiguration {
    /**
     * The adapter version
     */
    adapterVersion: pulumi.Input<string>;
    /**
     * The name of the configuration
     */
    name: pulumi.Input<string>;
    /**
     * The ID of the project
     */
    projectId: pulumi.Input<number>;
}

export interface SnowflakeSemanticLayerCredentialCredential {
    /**
     * The type of Snowflake credential ('password' or 'keypair')
     */
    authType: pulumi.Input<string>;
    /**
     * The internal credential ID
     */
    credentialId?: pulumi.Input<number>;
    /**
     * The catalog to connect use
     */
    database?: pulumi.Input<string>;
    /**
     * The ID of this resource. Contains the project ID and the credential ID.
     */
    id?: pulumi.Input<string>;
    /**
     * Whether the Snowflake credential is active
     */
    isActive?: pulumi.Input<boolean>;
    /**
     * Number of threads to use
     */
    numThreads: pulumi.Input<number>;
    /**
     * The password for the Snowflake account
     */
    password?: pulumi.Input<string>;
    /**
     * The private key for the Snowflake account
     */
    privateKey?: pulumi.Input<string>;
    /**
     * The passphrase for the private key
     */
    privateKeyPassphrase?: pulumi.Input<string>;
    /**
     * Project ID to create the Snowflake credential in
     */
    projectId: pulumi.Input<number>;
    /**
     * The role to assume
     */
    role?: pulumi.Input<string>;
    /**
     * The schema where to create models. This is an optional field ONLY if the credential is used for Semantic Layer configuration, otherwise it is required.
     */
    schema?: pulumi.Input<string>;
    /**
     * This field indicates that the credential is used as part of the Semantic Layer configuration. It is used to create a Snowflake credential for the Semantic Layer.
     */
    semanticLayerCredential?: pulumi.Input<boolean>;
    /**
     * The username for the Snowflake account. This is an optional field ONLY if the credential is used for Semantic Layer configuration, otherwise it is required.
     */
    user?: pulumi.Input<string>;
    /**
     * The warehouse to use
     */
    warehouse?: pulumi.Input<string>;
}
