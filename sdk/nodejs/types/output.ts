// *** WARNING: this file was generated by the Pulumi Terraform Bridge (tfgen) Tool. ***
// *** Do not edit by hand unless you're certain you know what you are doing! ***

import * as pulumi from "@pulumi/pulumi";
import * as inputs from "../types/input";
import * as outputs from "../types/output";

export interface GetEnvironmentsEnvironment {
    /**
     * A connection ID (used with Global Connections)
     */
    connectionId: number;
    /**
     * Credential ID to create the environment with. A credential is not required for development environments but is required for deployment environments
     */
    credentialsId: number;
    /**
     * The custom branch name to use
     */
    customBranch: string;
    /**
     * Version number of dbt to use in this environment.
     */
    dbtVersion: string;
    /**
     * The type of deployment environment (currently 'production', 'staging' or empty)
     */
    deploymentType: string;
    /**
     * The ID of the environment
     */
    environmentId: number;
    /**
     * The ID of the extended attributes applied
     */
    extendedAttributesId: number;
    /**
     * The name of the environment
     */
    name: string;
    /**
     * The project ID to which the environment belong
     */
    projectId: number;
    /**
     * The type of environment (must be either development or deployment)
     */
    type: string;
    /**
     * Whether to use a custom git branch in this environment
     */
    useCustomBranch: boolean;
}

export interface GetGroupGroupPermission {
    /**
     * Whether access should be provided for all projects or not.
     */
    allProjects: boolean;
    /**
     * Set of permissions to apply. The permissions allowed are the same as the ones for the `dbtcloud.Group` resource.
     */
    permissionSet: string;
    /**
     * Project ID to apply this permission to for this group.
     */
    projectId: number;
    /**
     * What types of environments to apply Write permissions to.
     */
    writableEnvironmentCategories: string[];
}

export interface GetGroupUsersUser {
    email: string;
    id: number;
}

export interface GetJobJobCompletionTriggerCondition {
    /**
     * The ID of the job that would trigger this job after completion.
     */
    jobId: number;
    /**
     * The ID of the project where the trigger job is running in.
     */
    projectId: number;
    /**
     * List of statuses to trigger the job on.
     */
    statuses: string[];
}

export interface GetJobsJob {
    /**
     * The version of dbt used for the job. If not set, the environment version will be used.
     */
    dbtVersion: string;
    /**
     * The ID of the environment this job defers to
     */
    deferringEnvironmentId: number;
    /**
     * [Deprecated - deferral is now set at the environment level] The ID of the job definition this job defers to
     */
    deferringJobDefinitionId: number;
    /**
     * The description of the job
     */
    description: string;
    /**
     * Details of the environment the job is running in
     */
    environment: outputs.GetJobsJobEnvironment;
    /**
     * The ID of environment
     */
    environmentId: number;
    /**
     * The list of steps to run in the job
     */
    executeSteps: string[];
    execution: outputs.GetJobsJobExecution;
    /**
     * Whether the job generate docs
     */
    generateDocs: boolean;
    /**
     * The ID of the job
     */
    id: number;
    /**
     * Whether the job is triggered by the completion of another job
     */
    jobCompletionTriggerCondition: outputs.GetJobsJobJobCompletionTriggerCondition;
    /**
     * The type of job (e.g. CI, scheduled)
     */
    jobType: string;
    /**
     * The name of the job
     */
    name: string;
    /**
     * The ID of the project
     */
    projectId: number;
    /**
     * Whether the job test source freshness
     */
    runGenerateSources: boolean;
    schedule: outputs.GetJobsJobSchedule;
    settings: outputs.GetJobsJobSettings;
    triggers: outputs.GetJobsJobTriggers;
    /**
     * Whether the CI job should be automatically triggered on draft PRs
     */
    triggersOnDraftPr: boolean;
}

export interface GetJobsJobEnvironment {
    /**
     * Type of deployment environment: staging, production
     */
    deploymentType: string;
    /**
     * ID of the environment
     */
    id: number;
    /**
     * Name of the environment
     */
    name: string;
    projectId: number;
    /**
     * Environment type: development or deployment
     */
    type: string;
}

export interface GetJobsJobExecution {
    /**
     * The number of seconds before the job times out
     */
    timeoutSeconds: number;
}

export interface GetJobsJobJobCompletionTriggerCondition {
    condition: outputs.GetJobsJobJobCompletionTriggerConditionCondition;
}

export interface GetJobsJobJobCompletionTriggerConditionCondition {
    jobId: number;
    projectId: number;
    statuses: string[];
}

export interface GetJobsJobSchedule {
    /**
     * The cron schedule for the job. Only used if triggers.schedule is true
     */
    cron: string;
}

export interface GetJobsJobSettings {
    /**
     * Value for `target.name` in the Jinja context
     */
    targetName: string;
    /**
     * Number of threads to run dbt with
     */
    threads: number;
}

export interface GetJobsJobTriggers {
    /**
     * Whether the job runs automatically on PR creation
     */
    gitProviderWebhook: boolean;
    /**
     * Whether the job runs automatically on PR creation
     */
    githubWebhook: boolean;
    /**
     * Whether the job runs automatically once a PR is merged
     */
    onMerge: boolean;
    /**
     * Whether the job runs on a schedule
     */
    schedule: boolean;
}

export interface GetServiceTokenServiceTokenPermission {
    /**
     * Whether or not to apply this permission to all projects for this service token
     */
    allProjects: boolean;
    /**
     * Set of permissions to apply
     */
    permissionSet: string;
    /**
     * Project ID to apply this permission to for this service token
     */
    projectId: number;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories: string[];
}

export interface GetUsersUser {
    /**
     * Email for the user
     */
    email: string;
    /**
     * ID of the user
     */
    id: number;
}

export interface GlobalConnectionBigquery {
    /**
     * OAuth Client ID
     */
    applicationId?: string;
    /**
     * OAuth Client Secret
     */
    applicationSecret?: string;
    /**
     * Auth Provider X509 Cert URL for the Service Account
     */
    authProviderX509CertUrl: string;
    /**
     * Auth URI for the Service Account
     */
    authUri: string;
    /**
     * Service Account email
     */
    clientEmail: string;
    /**
     * Client ID of the Service Account
     */
    clientId: string;
    /**
     * Client X509 Cert URL for the Service Account
     */
    clientX509CertUrl: string;
    /**
     * Dataproc cluster name for PySpark workloads
     */
    dataprocClusterName?: string;
    /**
     * Google Cloud region for PySpark workloads on Dataproc
     */
    dataprocRegion?: string;
    /**
     * Project to bill for query execution
     */
    executionProject?: string;
    /**
     * The GCP project ID to use for the connection
     */
    gcpProjectId: string;
    /**
     * URI for a Google Cloud Storage bucket to host Python code executed via Datapro
     */
    gcsBucket?: string;
    /**
     * Service Account to impersonate when running queries
     */
    impersonateServiceAccount?: string;
    /**
     * Maximum timeout for the job creation step
     */
    jobCreationTimeoutSeconds?: number;
    /**
     * Total number of seconds to wait while retrying the same query
     */
    jobRetryDeadlineSeconds?: number;
    /**
     * Location to create new Datasets in
     */
    location?: string;
    /**
     * Max number of bytes that can be billed for a given BigQuery query
     */
    maximumBytesBilled?: number;
    /**
     * The priority with which to execute BigQuery queries (batch or interactive)
     */
    priority?: string;
    /**
     * Private Key for the Service Account
     */
    privateKey: string;
    /**
     * Private Key ID for the Service Account
     */
    privateKeyId: string;
    /**
     * Number of retries for queries
     */
    retries: number;
    /**
     * OAuth scopes for the BigQuery connection
     */
    scopes: string[];
    /**
     * Timeout in seconds for queries
     */
    timeoutSeconds: number;
    /**
     * Token URI for the Service Account
     */
    tokenUri: string;
}

export interface GlobalConnectionDatabricks {
    /**
     * Catalog name if Unity Catalog is enabled in your Databricks workspace.
     */
    catalog?: string;
    /**
     * Required to enable Databricks OAuth authentication for IDE developers.
     */
    clientId?: string;
    /**
     * Required to enable Databricks OAuth authentication for IDE developers.
     */
    clientSecret?: string;
    /**
     * The hostname of the Databricks cluster or SQL warehouse.
     */
    host: string;
    /**
     * The HTTP path of the Databricks cluster or SQL warehouse.
     */
    httpPath: string;
}

export interface GlobalConnectionSnowflake {
    /**
     * The Snowflake account name
     */
    account: string;
    /**
     * Whether to allow Snowflake OAuth for the connection. If true, the `oauthClientId` and `oauthClientSecret` fields must be set
     */
    allowSso: boolean;
    /**
     * If true, the snowflake client will keep connections for longer than the default 4 hours. This is helpful when particularly long-running queries are executing (> 4 hours)
     */
    clientSessionKeepAlive: boolean;
    /**
     * The default database for the connection
     */
    database: string;
    /**
     * OAuth Client ID. Required to allow OAuth between dbt Cloud and Snowflake
     */
    oauthClientId?: string;
    /**
     * OAuth Client Secret. Required to allow OAuth between dbt Cloud and Snowflake
     */
    oauthClientSecret?: string;
    /**
     * The Snowflake role to use when running queries on the connection
     */
    role?: string;
    /**
     * The default Snowflake Warehouse to use for the connection
     */
    warehouse: string;
}

export interface GroupGroupPermission {
    /**
     * Whether access should be provided for all projects or not.
     */
    allProjects: boolean;
    /**
     * Set of permissions to apply. The permissions allowed are the same as the ones for the `dbtcloud.Group` resource.
     */
    permissionSet: string;
    /**
     * Project ID to apply this permission to for this group.
     */
    projectId?: number;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories: string[];
}

export interface GroupPartialPermissionsGroupPermission {
    /**
     * Whether access should be provided for all projects or not.
     */
    allProjects: boolean;
    /**
     * Set of permissions to apply. The permissions allowed are the same as the ones for the `dbtcloud.Group` resource.
     */
    permissionSet: string;
    /**
     * Project ID to apply this permission to for this group.
     */
    projectId?: number;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories?: string[];
}

export interface JobJobCompletionTriggerCondition {
    /**
     * The ID of the job that would trigger this job after completion.
     */
    jobId: number;
    /**
     * The ID of the project where the trigger job is running in.
     */
    projectId: number;
    /**
     * List of statuses to trigger the job on. Possible values are `success`, `error` and `canceled`.
     */
    statuses: string[];
}

export interface ServiceTokenServiceTokenPermission {
    /**
     * Whether or not to apply this permission to all projects for this service token
     */
    allProjects: boolean;
    /**
     * Set of permissions to apply
     */
    permissionSet: string;
    /**
     * Project ID to apply this permission to for this service token
     */
    projectId?: number;
    /**
     * What types of environments to apply Write permissions to.
     * Even if Write access is restricted to some environment types, the permission set will have Read access to all environments.
     * The values allowed are `all`, `development`, `staging`, `production` and `other`.
     * Not setting a value is the same as selecting `all`.
     * Not all permission sets support environment level write settings, only `analyst`, `databaseAdmin`, `developer`, `gitAdmin` and `teamAdmin`.
     */
    writableEnvironmentCategories: string[];
}

